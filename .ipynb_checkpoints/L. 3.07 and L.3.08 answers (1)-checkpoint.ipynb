{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r97zMfY1myrW",
    "outputId": "d4861bc1-79f4-4c02-c5c4-d7d5059de23a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "# prep: import modules and get pwd\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import getpass  # To get the password without showing the input\n",
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvASXwGtmyrd"
   },
   "outputs": [],
   "source": [
    "# get the data\n",
    "connection_string = 'mysql+pymysql://root:' + password + '@localhost/bank'\n",
    "engine = create_engine(connection_string)\n",
    "query = '''select t.type, t.operation, t.amount as t_amount, t.balance, t.k_symbol, l.amount as l_amount, l.duration, l.payments, l.status\n",
    "from trans t\n",
    "left join loan l\n",
    "on t.account_id = l.account_id;'''\n",
    "\n",
    "data = pd.read_sql_query(query, engine)\n",
    "data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pBKmkFbmyre"
   },
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6WsDTJZ8BmcJ"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgLik82qmyrf"
   },
   "outputs": [],
   "source": [
    "# Activity 1\n",
    "#  pd.read_sql_table will accept a table name and will retrieve the whole table. \n",
    "#  You can also read a whole table with pd.read_sql. Try it on the table 'district'.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "error",
     "timestamp": 1685020146238,
     "user": {
      "displayName": "Jan Molendijk",
      "userId": "00665875236133738524"
     },
     "user_tz": -120
    },
    "id": "rn9906pcmyrf",
    "outputId": "4973c1b4-647d-4f1c-befc-f1d8009e48b1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c2e707627e03>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdistrict1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'district'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdistrict1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8F8oOS9myrf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# End Activity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Hpcxl_7myrf"
   },
   "outputs": [],
   "source": [
    "data['status'].value_counts(dropna=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TDBRctWmyrg"
   },
   "outputs": [],
   "source": [
    "data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KkC4ie7Zmyrg"
   },
   "outputs": [],
   "source": [
    "data.dtypes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYGheK8wmyrg"
   },
   "outputs": [],
   "source": [
    "data.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PlKRZXiJmyrh"
   },
   "outputs": [],
   "source": [
    "data = data[~data['status'].isna()] # what rows are we dropping here?\n",
    "#data = data[data['status'].isna()==False] \n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Qk7Bce5myrh"
   },
   "outputs": [],
   "source": [
    "data.describe().T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImtPvvKsBmcV"
   },
   "outputs": [],
   "source": [
    "data.duration.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lK-pzuKHmyrh"
   },
   "outputs": [],
   "source": [
    "data['duration'] = data['duration'].astype('object') # This will be treated as categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZMLTJhFBmcW"
   },
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HWG9wVnSmyri"
   },
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GW0xT2k-myri"
   },
   "outputs": [],
   "source": [
    "data['operation'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzTEarU1myri"
   },
   "outputs": [],
   "source": [
    "def cleanOperation(x):\n",
    "    x = x.lower()\n",
    "    if 'vyber' in x:\n",
    "        return \"vyber\"\n",
    "    elif 'prevod' in x:\n",
    "        return \"prevod\"\n",
    "    elif 'vklad' in x:\n",
    "        return 'vklad'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "data['operation'] = list(map(cleanOperation, data['operation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFrUd8Qomyri"
   },
   "outputs": [],
   "source": [
    "data['operation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stVSuVQRmyrj"
   },
   "outputs": [],
   "source": [
    "data['k_symbol'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "820iye85myrj"
   },
   "outputs": [],
   "source": [
    "data['k_symbol'].value_counts().index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEqES2o3myrj"
   },
   "outputs": [],
   "source": [
    "def cleankSymbol(x):\n",
    "    if x in ['', ' ']:\n",
    "        return 'unknown'\n",
    "    else:\n",
    "        return x.lower()\n",
    "\n",
    "data['k_symbol'] = list(map(cleankSymbol, data['k_symbol']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_6MaquMmyrj"
   },
   "outputs": [],
   "source": [
    "data['k_symbol'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AgQ-rOkJmyrj"
   },
   "outputs": [],
   "source": [
    "#data = data[~data['k_symbol'].isin(['pojistne', 'sankc. urok', 'uver'])] # ~ : NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PlK1LXgABmcc"
   },
   "outputs": [],
   "source": [
    "data['k_symbol'].isin(['pojistne', 'sankc. urok', 'uver'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6uHtGXRBmcd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data['k_symbol'] = np.where(data['k_symbol'].isin(['pojistne', 'sankc. urok', 'uver']), 'other', data['k_symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvS_qPdqBmce"
   },
   "outputs": [],
   "source": [
    "data['k_symbol'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5gk7lVpFBmce"
   },
   "outputs": [],
   "source": [
    "data['k_symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZf7s7GAmyrk"
   },
   "outputs": [],
   "source": [
    "# discuss disadvantages and alternatives to dropping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cANrMGI3myrk"
   },
   "outputs": [],
   "source": [
    "data['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6V7_uMGBmcg"
   },
   "outputs": [],
   "source": [
    "data['operation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V77dAiicmyrk"
   },
   "outputs": [],
   "source": [
    "# Activity 2:\n",
    "# Explore values in columns TYPE and OPERATION. \n",
    "# How many different loans of each type and operation are there? \n",
    "# How many rows for each combination? \n",
    "# (You may want to check out pandas.crosstab function.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c747Nstxmyrk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VoUzV98wmyrk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s59mwC8Gmyrk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBBW7lhrmyrl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62M1nuY6myrl"
   },
   "outputs": [],
   "source": [
    "pd.crosstab(data.type, data.operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4LkXnWtxBmcl"
   },
   "outputs": [],
   "source": [
    "pd.crosstab(data['duration'],data['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMnSwY1Hmyrl"
   },
   "outputs": [],
   "source": [
    "#End Activity 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8HlGeRnfmyrl"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4chcGB59myrl"
   },
   "outputs": [],
   "source": [
    "# look for multicolinearity (some columns having almost identical correlation to other variables)\n",
    "# why can't we look for correlation with our target variable (status)?\n",
    "corr_matrix=data.corr()  # default\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax = sns.heatmap(corr_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "twruFD1rmyrl"
   },
   "outputs": [],
   "source": [
    "# look at the scale and distribution of values\n",
    "sns.displot(data['t_amount'], kde=True)\n",
    "plt.show()\n",
    "\n",
    "sns.displot(data['l_amount'], kde=True)\n",
    "plt.show()\n",
    "\n",
    "sns.displot(data['balance'], kde=True)\n",
    "plt.show()\n",
    "\n",
    "sns.displot(data['payments'], kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9KUOmU4Kmyrm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_num = data.select_dtypes(include = np.number)\n",
    "X_cat = data.select_dtypes(include = object)\n",
    "\n",
    "# Scaling data\n",
    "transformer = MinMaxScaler().fit(X_num)\n",
    "x_normalized = transformer.transform(X_num)\n",
    "x_norm = pd.DataFrame(x_normalized, columns=X_num.columns)\n",
    "x_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1H7bVLI9BmdL"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Whoa, One step back please. What did I do wrong here?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMZeuW-XBmdM"
   },
   "outputs": [],
   "source": [
    "# Need to X-y split and train-test-split BEFORE I apply transformations, \n",
    "# then train transformation on training set only\n",
    "y = data['status']\n",
    "X = data.drop('status', axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-p8RNB7BmdM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_num = X_train.select_dtypes(include = np.number)\n",
    "\n",
    "# Scaling data\n",
    "transformer = MinMaxScaler().fit(X_train_num) # need to keep transformer\n",
    "X_train_normalized = transformer.transform(X_train_num)\n",
    "X_train_norm = pd.DataFrame(X_train_normalized, columns=X_num.columns)\n",
    "X_train_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3zKkBWymyrm"
   },
   "outputs": [],
   "source": [
    "X_train_categorical = X_train.select_dtypes(include = object)\n",
    "X_train_cat = pd.get_dummies(X_train_categorical, \n",
    "                             columns=['type', 'operation', 'k_symbol', 'duration'],\n",
    "                             drop_first=True)\n",
    "X_train_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZAv0_WvJmyrm"
   },
   "outputs": [],
   "source": [
    "# Activity 3\n",
    "# Explore visually the transformed numerical columns. What do you see?\n",
    "\n",
    "# Another typical transformation for numerical columns is to take the logarithm. \n",
    "# Apply the log transform to columns balance and t_ammount and compare the results with the scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMR9c6-Omyrm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5C05rQJBmdP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mx1BEfS3myrn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s17sSbjumyrn",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q-HgdiaPmyrn"
   },
   "outputs": [],
   "source": [
    "# End Activity 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S0htv5PKmyrn"
   },
   "outputs": [],
   "source": [
    "# build X_train and y_train\n",
    "# remember: y = data['status'], y_train selected in train_test_split\n",
    "X_train_transformed = np.concatenate([X_train_norm, X_train_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oYVSxoXimyrn"
   },
   "outputs": [],
   "source": [
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1E8DiZc8myro"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classification = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                  multi_class='multinomial').fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eyAugyQomyro"
   },
   "outputs": [],
   "source": [
    "classification = LogisticRegression(random_state=0, solver='saga',\n",
    "                  multi_class='multinomial').fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4p-ypzaBmyro"
   },
   "outputs": [],
   "source": [
    "# Can we now make predictions on the X_test?\n",
    "predictions = classification.predict(X_test)\n",
    "classification.score(X_test, y_test)\n",
    "\n",
    "\n",
    "# NO - need to perform transformations on the X_test as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lInbeUXvBmdV"
   },
   "outputs": [],
   "source": [
    "# for numericals\n",
    "X_test_num = X_test.select_dtypes(include = np.number)\n",
    "\n",
    "# Scaling data\n",
    "# we use the transformer that was trained on the training data\n",
    "X_test_normalized = transformer.transform(X_test_num)\n",
    "X_test_norm = pd.DataFrame(X_test_normalized)\n",
    "X_test_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuY9dR9UBmdV"
   },
   "outputs": [],
   "source": [
    "# for categoricals\n",
    "X_test_categorical = X_test.select_dtypes(include = object)\n",
    "X_test_cat = pd.get_dummies(X_test_categorical, \n",
    "                            columns=['type', 'operation', 'k_symbol', 'duration'],\n",
    "                            drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PcUyU1noBmdW",
    "outputId": "ce92951f-a216-48c9-a3a0-e61870d860a5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_VYBER</th>\n",
       "      <th>type_VYDAJ</th>\n",
       "      <th>operation_unknown</th>\n",
       "      <th>operation_vklad</th>\n",
       "      <th>operation_vyber</th>\n",
       "      <th>k_symbol_sipo</th>\n",
       "      <th>k_symbol_sluzby</th>\n",
       "      <th>k_symbol_unknown</th>\n",
       "      <th>k_symbol_urok</th>\n",
       "      <th>duration_24.0</th>\n",
       "      <th>duration_36.0</th>\n",
       "      <th>duration_48.0</th>\n",
       "      <th>duration_60.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>468383</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138741</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716908</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251868</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261611</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type_VYBER  type_VYDAJ  operation_unknown  operation_vklad  \\\n",
       "468383           0           0                  1                0   \n",
       "138741           0           1                  0                0   \n",
       "716908           0           1                  0                0   \n",
       "251868           0           1                  0                0   \n",
       "261611           0           0                  0                1   \n",
       "\n",
       "        operation_vyber  k_symbol_sipo  k_symbol_sluzby  k_symbol_unknown  \\\n",
       "468383                0              0                0                 0   \n",
       "138741                0              1                0                 0   \n",
       "716908                1              0                1                 0   \n",
       "251868                0              0                0                 1   \n",
       "261611                0              0                0                 1   \n",
       "\n",
       "        k_symbol_urok  duration_24.0  duration_36.0  duration_48.0  \\\n",
       "468383              1              0              0              0   \n",
       "138741              0              0              0              0   \n",
       "716908              0              0              0              0   \n",
       "251868              0              1              0              0   \n",
       "261611              0              1              0              0   \n",
       "\n",
       "        duration_60.0  \n",
       "468383              0  \n",
       "138741              1  \n",
       "716908              1  \n",
       "251868              0  \n",
       "261611              0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QUJRdOW2BmdX"
   },
   "outputs": [],
   "source": [
    "X_train_cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U8OZCVtcBmdX"
   },
   "outputs": [],
   "source": [
    "X_test_cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n2zNCM9eBmdY"
   },
   "outputs": [],
   "source": [
    "# verify that dummies columns are in the same order and that the same column was dropped\n",
    "list(zip(list(X_train_cat.columns),list(X_test_cat.columns)))\n",
    "# not needed if you treat each dataframe with one_hot_encoder and save the encode (and the column names)\n",
    "\n",
    "# X_test_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6wT9EfPZBmdZ"
   },
   "outputs": [],
   "source": [
    "list(X_train_cat.columns)==list(X_test_cat.columns)\n",
    "# if the anser here is True, we got lucky (same order of columns), of not we have to reorder\n",
    "# therefore it is much easier to use one_hot_ecoder: you fit on the train set, then reuse tat encoder on both train and test\n",
    "# and you are guaranteed the same order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpPB1dTZBmdZ"
   },
   "outputs": [],
   "source": [
    "X_test_transformed = np.concatenate([X_test_norm, X_test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3VQGE_8RBmda",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now we can make predictions on the test set:\n",
    "predictions = classification.predict(X_test_transformed)\n",
    "predictions\n",
    "classification.score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kYXgWEABmda"
   },
   "source": [
    "order of steps\n",
    "\n",
    "- get data\n",
    "- check and clean data (nulls, fixing typos, outliers, distrubutions,...)\n",
    "- data exploration\n",
    "- check for multicolinearity\n",
    "- select features\n",
    "\n",
    "- X/y split (feature/target) : X, y\n",
    "- train/test split           : X_train, X_test, y_train, y_test\n",
    "- num/cat split              : X_train_num, X_train_cat, X_test_num, X_test_cat\n",
    "\n",
    "- fit transformer on X_train_num\n",
    "- run transformer on X_train_num     : X_train_normalized\n",
    "- run same transformer on X_test_num : X_test_normalized\n",
    "- fit encoder on X_train_cat\n",
    "- run encoder on X_train_cat         : X_train_encoded\n",
    "- run same encoder on X_test_cat     : X_test_encoded\n",
    "\n",
    "- concat X_train_normalized and X_train_encoded : X_train_transformed\n",
    "- choose model (LienarRegression on numeric target, LogisticRegression(=classification!) on categorical target)\n",
    "- fit (train) model in X_train_transformed      : model\n",
    "- concat X_test_normalized and X_test_encoded   : X_test_transformed\n",
    "- make predictions using X_test_transfomed      : model.predict -> predictions\n",
    "- compute score using predictions and y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKXKIjcPmyro"
   },
   "outputs": [],
   "source": [
    "print(y_test.value_counts())\n",
    "# As you would notice here, there is a huge imbalance in the data among the different classes. \n",
    "# We will talk more about imbalance and how to resolve it later (tomorrow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fuNSGscmyro"
   },
   "outputs": [],
   "source": [
    "pd.Series(predictions).value_counts()\n",
    "# This shows that the disparity in the numbers are amplified by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YhhzlfOmyrp"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JwAsF1akmyrp"
   },
   "outputs": [],
   "source": [
    "# predicted | A | B | C | D |\n",
    "# --------------------------\n",
    "# actual  A | + |  |   |   |\n",
    "# --------------------------\n",
    "#         B |   | + |   |   |\n",
    "# --------------------------\n",
    "#         C |   |   | + |   |\n",
    "# --------------------------\n",
    "#         D |   |   |   | + |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "salXbiJgmyrp"
   },
   "outputs": [],
   "source": [
    "# bonus: KNN classifier: look at nearest neighbours and use the majority to determine class\n",
    "from sklearn import neighbors\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "clf.fit(X_train_transformed, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFn1kGuLBmdh"
   },
   "outputs": [],
   "source": [
    "predictions_clf = clf.predict(X_test_transformed)\n",
    "clf.score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_mftgwJmyrp"
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3W0t-HHGmyrp"
   },
   "outputs": [],
   "source": [
    "pd.Series(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzHpesNAmyrp"
   },
   "outputs": [],
   "source": [
    "pd.Series(predictions_clf).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZeAzI8fmyrq"
   },
   "outputs": [],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DjOcCfGiBmdj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
